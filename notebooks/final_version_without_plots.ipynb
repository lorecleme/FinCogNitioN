{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6edf83",
   "metadata": {},
   "source": [
    "# FinCogNitioN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acd6da",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The classification of cetacean species has posed a considerable challenge due to their vast morphological and ecological diversity. The present project aimed to categorize 30 species of whales and dolphins by examining the dorsal fin as it protrudes out of the water. It is worth noting that, akin to the human fingerprint, the dorsal fin of cetaceans is unique and can be used to identify individual cetacean species $^{[1]}$. The HappyWhale $^{[2]}$  dataset from Kaggle was utilized to train our models, providing us with three primary pieces of information: an image of the fin in the sea, the cetacean species, and individual IDs. More than one model was implemented to monitor our progress and evaluate the obtained outcomes. Our best algorithm developed entirely from scratch, achieved an accuracy of $x$, a test loss of $y$, and an average F1 score of $z$. Additionally, we attempted to fine-tune a VGG-16 model, resulting in an accuracy of $x$, a test loss of $y$, and an average F1 score of $z$. Our main hurdle was the datasetâ€™s imbalanced nature, with the class possessing the most samples containing $x$ individuals, while the class with the fewest samples had only $y$ individuals. Despite this impediment, we were able to attain satisfactory results, thereby confirming our hypothesis that individual cetacean species can be discerned via analysis of their dorsal fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6a7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import used libraries\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from numpy import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_images_from_dataloader(dataloader, num_images=16):\n",
    "    # Create a figure with 4 rows and 4 columns\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "    # Plot images from the dataloader on each subplot\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        for j in range(4):\n",
    "            if i * 4 + j >= num_images:\n",
    "                break\n",
    "\n",
    "            ax = axes[i, j]\n",
    "            ax.imshow(images[j].permute(1, 2, 0))  # Permute dimensions for proper image display\n",
    "            ax.set_title(f'Image {i * 4 + j + 1}')\n",
    "            ax.axis('off')\n",
    "\n",
    "        if (i + 1) * 4 >= num_images:\n",
    "            break\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fb65a",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The present research utilized the HappyWhale Kaggle dataset, boasting a substantial 62.06 GB in size and comprising 50,133 images of cetaceans, each annotated with the respective species and individual IDs. Of note, this dataset is compiled from a collection of over 15,000 individual marine mammals belonging to 30 distinct species, obtained via 28 diverse research organizations. The integration of such data from a range of sources presented various logistical hurdles, such as discrepancies in image size and varied representations of both RGB and grayscale formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9e61241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['species'] = df['species'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6e5cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['species'].value_counts().index\n",
    "n_samples = df['species'].value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "299a3bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Plot the countplot using Seaborn\n",
    "sns.barplot(x=categories, y=n_samples, ax=ax)\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Sample Distribution by Category')\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('Sample Count')\n",
    "\n",
    "# Customize the appearance\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd316b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset previously preprocessed in slices in a Colab file aside. We will still report the preprocessing applied in the next cells\n",
    "data0 = torch.load('0_to_15k.pt')\n",
    "data1 = torch.load('firstslice.pt')\n",
    "data2 = torch.load('from_40.pt')\n",
    "data3 = torch.load('21_31.pt')\n",
    "data4 = torch.load('31_41.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518a4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the slices of the dataset\n",
    "DATA = torch.utils.data.ConcatDataset([data0, data1, data2, data3, data4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df37ce3",
   "metadata": {},
   "source": [
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "In order to preprocess our dataset effectively, we had to conduct an analysis of its distribution to determine the appropriate model definition. During this phase, two major challenges were encountered, namely dataset imbalance and image standardization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338aef2",
   "metadata": {},
   "source": [
    "#### Image Standardization\n",
    "Initially, we converted the species values in the dataset into numerical values to enhance statistical analysis. This revealed the issues regarding **dataset imbalance**, but we decided to deal with this issue after solving the **image standardization** issue.\n",
    "\n",
    "About the last mentioned issue, we employed the _pytorch.Transform_   function to resize the images to $224 \\times224$  dimensions and then we turned each of them into a vector to make it processable by the rest of the nertowrk. As for the channel sizing issue, initially, we experimented with the _Grayscale_ transform, but realized that forcing the channels to $1$ would create unnecessary challenges for the fin recognition while forcing them to $3$ would have made our network uselessly heavier, since the grayscaled images would have had $3$ channels with the same value in each of them. Eventually, we resolved this issue by using _Image.convert(â€˜RGBâ€™)_  when loading the images in the Dataset object to maintain the original number of channels in each image. \n",
    "\n",
    "Since there are no random transformations applied to our dataset. We decided to preprocess our data all at once in a separate file, in this way, we lightened a lot our training process, since our DataLoader did not had to preprocess them at every code run. Thus we sliced the original dataset, we applied transformation to each slices and then we uploaded the slices, as shown in the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations applied in the Colab file\n",
    "transformation = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #image resizing following standards\n",
    "    transforms.ToTensor()#turn image into tensor\n",
    "])\n",
    "new_species = DATA['species'].astype('category').cat.codes  \n",
    "\n",
    "DATA['species'] = new_species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc476686",
   "metadata": {},
   "source": [
    "One important step in the definition of our Dataset instance is the loop in the _init_ function. Thanks to this at the first iteration everything is preprocessed at once, and we do not have to iterate it batch by batch as it happens in normal iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b48816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class ImageDatasetVGG(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.pairs = list()\n",
    "\n",
    "        for idx in tqdm(range(len(annotations_file))):\n",
    "\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "            image = Image.open(img_path).convert('RGB') ## this is being done because before we were dealing just with greyscale images ðŸ˜¦\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "            image = self.transform(image)\n",
    "            self.pairs.append((image, label))\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self): #find dataset length\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx): #get the pair img-label in a tuple\n",
    "        pair = self.pairs[idx]\n",
    "        image, label = pair[0], pair[1]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87833b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find size of the valuation set considering that it will be the 20% of our dataset\n",
    "val_size = int(len(DATA) - len(DATA)*0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fc2a2",
   "metadata": {},
   "source": [
    "In the subsequent cell, we opted to assign a seed value to our training and validation split. The purpose behind this decision was to assess whether the model had genuinely learned by exposing it to images that it supposedly had not encountered before. To ensure the reliability of our findings, we conducted multiple iterations instead of retraining the entire model from scratch, as it was unnecessary. However, over time, we observed that the pool of previously unseen images was depleted, prompting the model to rely on images from the training set, leading to overfitting. Consequently, we introduced the concept of a seed value to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dab5d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f96d38ccfd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = torch.Generator()\n",
    "generator.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add28ba",
   "metadata": {},
   "source": [
    "##### Dataset Imbalance\n",
    "Then we proceeded by addressing the issue of the  dataset imbalance, which we addressed by randomly splitting the data into training ($80\\%$) and test ($20\\%$) sets utilizing the _torch.utils.data.dataset.randomsplit_  function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb1dd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_val = torch.utils.data.random_split(DATA, (len(DATA)- val_size, val_size), generator=generator) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7891a",
   "metadata": {},
   "source": [
    "Then, to address the issue of imbalance, we made the decision to assign weighted samples from both the train sets. This involved determining the number of images corresponding to each label by counting the instances with identical labels obtainable from the Dataset object.\n",
    "\n",
    "In order to accomplish this, we employed the following cell to extract all the labels associated with the images in the train set. The labels were then transformed into a Series object to facilitate subsequent conversion into a NumPy array and facilitate analysis and calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6924121",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = list()\n",
    "for i in range(len(image_train)):\n",
    "    Y.append(image_train[i][1])\n",
    "    \n",
    "labels_on_train = pd.Series(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_new_species = labels_on_train.unique() #take unique instances of labels in the train set\n",
    "train_labels_np = np.array(labels_on_train) #turn the Series of labels into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679a769",
   "metadata": {},
   "source": [
    "Further, we dealt with the imbalance within the training set by implementing a weighted random sampler (_torch.utils.data.sampler.WeightedRandomSampler_ ), with no such balancing required for the validation set. Finally, we defined weights for each class in the training set based on an inverse proportion to their respective sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f81a168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# calculate the quantity of instances belonging to each class in the train set\n",
    "class_counts = Counter(labels_on_train)\n",
    "n_samples = len(train_labels_np)\n",
    "\n",
    "# calculates the weights for each class\n",
    "weights = [1.0 / class_counts[x] for x in train_labels_np]\n",
    "\n",
    "# crete a weigthed sampler which will further be applied only to the train set\n",
    "sampler = data.WeightedRandomSampler(weights, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b10d1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define tha DataLoader objects\n",
    "\n",
    "train_loader = DataLoader(image_train, batch_size=256, sampler=sampler)\n",
    "val_loader = DataLoader(image_val, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de825eb0",
   "metadata": {},
   "source": [
    "## The Model\n",
    "Our model was defined employing a **Convolutional Neural Network (CNN)** for its intended purpose. Drawing inspiration from the VGG model, we conducted numerous trials to ensure proper fitting of our data, ultimately arriving at the configuration detailed below.\n",
    "\n",
    "As evident in the subsequent cell, we constructed a **Fully Connected CNN** comprising a total of **9 CNN Blocks** and **3 Fully Connected**. The **LeakyReLU function** was selected as the activation function of choice. Additionally, to defeat the phenomenon overfitting, we made the deliberate choice to alternate some **Max Pooling layers** having a default stride value in the **Conv2D layer**, with some other layers without **Max Pooling layer** but having a greater stride than the default one in the **Conv2d layer**. This decision was motivated by our initial implementation, wherein we applied **Max Pooling** to all layers by default. However, after observing that our images had already been resized, we recognized that incorporating Max Pooling universally could significantly increase the risk of underfitting. On the other hand, completely omitting Max Pooling, even with an increase in stride value, would invariably lead to overfitting. Therefore, we struck a balance between these two techniques to achieve optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa54c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_classes=30):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ConvLayer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),   \n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.ConvLayer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(25088, 2048),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(256, num_classes))\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        x = self.ConvLayer1(inputs)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = self.ConvLayer4(x)\n",
    "        x = self.ConvLayer5(x)\n",
    "        x = self.ConvLayer6(x)\n",
    "        x = self.ConvLayer7(x)\n",
    "        x = self.ConvLayer8(x)\n",
    "        x = self.ConvLayer9(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "01a43a6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (ConvLayer1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (ConvLayer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (ConvLayer5): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer6): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer7): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer8): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (ConvLayer9): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model instantiation\n",
    "model = CNN(30)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b976f",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer\n",
    "We defined the **Cross Entropy Loss** the **AdamW optimizer** to be used in our train and test process. We decided to use the AdamW optiizer, insted of the traditional Adam optimizer because, in this new version of the algorithm, the weight decay is performed only after controlling the parameter-wise step size. The weight decay or regularization term does not end up in the moving averages and is thus only proportional to the weight itself. Thus, AdamW yields better training loss and that the models generalize much better than models trained with Adam allowing the new version to compete with stochastic gradient descent with momentum.\n",
    "\n",
    "\n",
    "In the last line of the cell below, we also added the **_ReduceLRonPlateau_** method, Pytorch documentation defines it as: \"Reduce learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This scheduler reads a metrics quantity and if no improvement is seen for a â€˜patienceâ€™ number of epochs, the learning rate is reduced.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53af3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "criterion = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(criterion, mode='min', factor=0.2, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8515135",
   "metadata": {},
   "source": [
    "## Train and Test Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894ad13",
   "metadata": {},
   "source": [
    "Before strting the train and test loop, we wanted to augment our data, in order to make our model more robust. Thus we applied some random transformations to our data and we aplied them in the train function. We used the _Compose_ method to add a random rotation and an horizontal flip to our data. Then we apply a random seed to this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_inside = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=25),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    #transforms.RandomVerticalFlip(p=0.3) ## we can observe that applying certain data augmentation techniques can be counterproductive,\n",
    "                                           # because we can never have fins upside down in nature\n",
    "])\n",
    "\n",
    "seed = np.random.randint(2147483647) \n",
    "random.seed(seed) \n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adf6a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function definition\n",
    "def train(model, loss_f, optim, dataloader):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = list() #instantiate the list that will contain all the losses reached at every iteration of the same epoch,\n",
    "                          #to associate its average to the current epoch. it will be emptied at the beginnign of the successive epoch\n",
    "    \n",
    "    train_loss = 0\n",
    "    n_batches = len(dataloader)\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        imgs, labels = batch[0], batch[1]\n",
    "        labels  = labels.type(torch.LongTensor)\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        imgs = transform_inside(imgs)\n",
    "        \n",
    "        ## -- forward pass -- ##\n",
    "        preds = model(imgs)\n",
    "        \n",
    "        ## -- computing the loss wrt G.T. -- ##\n",
    "        loss = loss_f(preds, labels)\n",
    "    \n",
    "        ## -- Backpropagation -- ##\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_losses.append(loss.item())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    print(f\"Average TRAIN Loss :: {train_loss/n_batches} \")\n",
    "    \n",
    "    return train_loss/n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67684d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function definition\n",
    "def test(model, iteratore, loss_f):\n",
    "    num_batches = len(iteratore)\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    test_losses = list()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(iteratore)):\n",
    "            img, labels = batch[0], batch[1]\n",
    "            labels  = labels.type(torch.LongTensor)\n",
    "            img, labels = img.cuda(), labels.cuda()\n",
    "            pred = model(img)\n",
    "            loss = loss_f(pred, labels)\n",
    "            test_loss += loss.item()\n",
    "            pred_indices = torch.argmax(pred, dim=1)\n",
    "            label_test = labels.cpu().float()\n",
    "            pred_indices = pred_indices.cpu().float()\n",
    "            distances = torch.where(pred_indices == label_test, torch.tensor(1), torch.tensor(0))\n",
    "            distances = distances.numpy()\n",
    "            accuracy += sum(distances)/len(label_test)\n",
    "            test_losses.append(loss.item())\n",
    "            \n",
    "    test_loss = test_loss / num_batches\n",
    "    accuracy_tot = accuracy / num_batches\n",
    "    \n",
    "    print(f\"Average TEST loss: {test_loss}, TEST accuracy: {accuracy_tot*100}%\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41daa5",
   "metadata": {},
   "source": [
    "We have seen, by changing the learning rate throughout the epochs (0.0003, 0.0001 and then 0.00008) iterations that at fifth epochs it authomatically set itself at 0.000016, thenks to the previously defined _scheduler_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77de23ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- epoch 1 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 1.4896469051670875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 1.4114030659198762, TEST accuracy: 56.50952675359713%\n",
      "\n",
      "\n",
      "----- epoch 2 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.8678165006030137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 1.3173662722110748, TEST accuracy: 58.51042603417266%\n",
      "\n",
      "\n",
      "----- epoch 3 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.6389024724626238 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 1.0565943270921707, TEST accuracy: 67.96804743705036%\n",
      "\n",
      "\n",
      "----- epoch 4 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.4996619135331196 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.889119666814804, TEST accuracy: 72.5275404676259%\n",
      "\n",
      "\n",
      "----- epoch 5 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:24<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.4181849975494822 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.9778119504451752, TEST accuracy: 70.88438624100719%\n",
      "\n",
      "\n",
      "----- epoch 6 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:24<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.36424861687004184 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.7568818897008895, TEST accuracy: 76.19576214028777%\n",
      "\n",
      "\n",
      "----- epoch 7 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.31410836309764034 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.7530745267868042, TEST accuracy: 76.98783160971223%\n",
      "\n",
      "\n",
      "----- epoch 8 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.27645658212862195 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.7390167534351348, TEST accuracy: 76.69535465377699%\n",
      "\n",
      "\n",
      "----- epoch 9 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.24840828757377187 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.6767748355865478, TEST accuracy: 79.3962876573741%\n",
      "\n",
      "\n",
      "----- epoch 10 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.22760778855366312 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.6494101196527481, TEST accuracy: 81.70814129946044%\n",
      "\n",
      "\n",
      "----- epoch 11 -----\n",
      "Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.2091596918121265 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.5974256888031959, TEST accuracy: 82.11162320143885%\n",
      "\n",
      "\n",
      "----- epoch 12 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.14412168645934695 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.4958669036626816, TEST accuracy: 85.35324865107914%\n",
      "\n",
      "\n",
      "----- epoch 13 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.13032634869502607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.48828853815793993, TEST accuracy: 86.01780294514387%\n",
      "\n",
      "\n",
      "----- epoch 14 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.11362138713241383 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.4756669968366623, TEST accuracy: 86.17714422212231%\n",
      "\n",
      "\n",
      "----- epoch 15 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.10774919490335853 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.5032013550400734, TEST accuracy: 85.42729878597122%\n",
      "\n",
      "\n",
      "----- epoch 16 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.1125239821708506 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.474676775932312, TEST accuracy: 86.16583295863309%\n",
      "\n",
      "\n",
      "----- epoch 17 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.10384158570627877 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.5068612083792686, TEST accuracy: 85.17542996852518%\n",
      "\n",
      "\n",
      "----- epoch 18 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.10405226590432179 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.4788355425000191, TEST accuracy: 87.02520795863309%\n",
      "\n",
      "\n",
      "----- epoch 19 -----\n",
      "Learning rate: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.09699072969994348 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.48728324472904205, TEST accuracy: 86.82476674910072%\n",
      "\n",
      "\n",
      "----- epoch 20 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.0691165329271536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.4249997168779373, TEST accuracy: 88.11692052607913%\n",
      "\n",
      "\n",
      "----- epoch 21 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:23<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.05582234190456617 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37942869067192075, TEST accuracy: 89.49591108363309%\n",
      "\n",
      "\n",
      "----- epoch 22 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.050621253889125244 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37570525109767916, TEST accuracy: 89.73899786420864%\n",
      "\n",
      "\n",
      "----- epoch 23 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.0524097067677671 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37679821699857713, TEST accuracy: 90.0093440872302%\n",
      "\n",
      "\n",
      "----- epoch 24 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.050356322976576676 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3792582795023918, TEST accuracy: 90.06639219874101%\n",
      "\n",
      "\n",
      "----- epoch 25 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.04564900016471459 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37450097054243087, TEST accuracy: 89.88393660071942%\n",
      "\n",
      "\n",
      "----- epoch 26 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.045137810040336505 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3953215330839157, TEST accuracy: 89.68040411420863%\n",
      "\n",
      "\n",
      "----- epoch 27 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.046608664225905566 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.38012940883636476, TEST accuracy: 89.95075033723022%\n",
      "\n",
      "\n",
      "----- epoch 28 -----\n",
      "Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.04416999884934467 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3781507596373558, TEST accuracy: 89.75649168165468%\n",
      "\n",
      "\n",
      "----- epoch 29 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.04316650188652573 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3724095359444618, TEST accuracy: 90.25812162769785%\n",
      "\n",
      "\n",
      "----- epoch 30 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03883587382140623 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3795531466603279, TEST accuracy: 89.93431036420864%\n",
      "\n",
      "\n",
      "----- epoch 31 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03764880392225874 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37125114351511, TEST accuracy: 90.09878035071942%\n",
      "\n",
      "\n",
      "----- epoch 32 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03605344145896898 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.37030441910028455, TEST accuracy: 90.29718412769783%\n",
      "\n",
      "\n",
      "----- epoch 33 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03913953495478839 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.36864716559648514, TEST accuracy: 90.49404226618705%\n",
      "\n",
      "\n",
      "----- epoch 34 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03503341631145234 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3760982617735863, TEST accuracy: 90.31516973920863%\n",
      "\n",
      "\n",
      "----- epoch 35 -----\n",
      "Learning rate: 2.0000000000000003e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:22<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TRAIN Loss :: 0.03633920937942661 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TEST loss: 0.3814066335558891, TEST accuracy: 90.29100157374101%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_loss = 100\n",
    "\n",
    "train_losses = list()\n",
    "test_losses = list()\n",
    "\n",
    "for epoch in range(35):\n",
    "    \n",
    "    print(f\"----- epoch {epoch+1} -----\")\n",
    "    print(f\"Learning rate:\", criterion.param_groups[0]['lr'])\n",
    "    train_losses.append(train(model, loss, criterion, train_loader))\n",
    "    t_loss = test(model, val_loader, loss)\n",
    "    \n",
    "    test_losses.append(t_loss)\n",
    "    \n",
    "    scheduler.step(t_loss)\n",
    "    \n",
    "    if epoch == 10 and criterion.param_groups[0]['lr'] == 0.0001:\n",
    "        new_lr = 0.00005\n",
    "        for param_group in criterion.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "            \n",
    "            \n",
    "    if epoch == 20 and criterion.param_groups[0]['lr'] == 0.00005:\n",
    "        new_lr = 0.000001\n",
    "        for param_group in criterion.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "\n",
    "     #right before possible overfitting, save checkpoints, that will be loaded at next train iteration to avoid restarting training from the beginning\n",
    "    if t_loss < min_loss:\n",
    "        min_loss = t_loss\n",
    "        torch.save(model, 'checkpoint_9_layers_including_dataAUGM.pth')\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7e953",
   "metadata": {},
   "source": [
    "## F1 Score Metric to check Dataset Imbalancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ef8f",
   "metadata": {},
   "source": [
    "We used the **F1 score** to find out the accuracy of our model estimation. Furthermore we used it to check if we have been able to solve our issue with dataset imbalance, because we were able to find accuracy both of the whole dataset and both of each individual class taken by the train test. And  we are totally satisfied by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab60e9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score, None = [0.97765741 0.96726505 0.91594828 0.94536817 0.7826087  0.92857143\n",
      " 0.83333333 0.72307692 0.98368679 0.85799257 0.71590909 0.46153846\n",
      " 0.66666667 0.88157895 0.87989019 0.90133333 0.94774775 0.81967213\n",
      " 0.92217327 0.78223496 0.58461538 0.7826087  0.52941176 0.4\n",
      " 0.87179487 0.93333333 0.93567251 0.80376766 0.75       0.6       ]\n",
      "F1 Score, micro = 0.9026584049570258\n",
      "F1 Score, macro = 0.8028485887112218\n",
      "F1 Score, avg = 0.903465985769893\n",
      "Average TEST loss: 0.3814066335558891, TEST accuracy: 90.29100157374101%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3814066335558891"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def test_with_f1(model, iteratore, loss_f):\n",
    "    LABELS = list()\n",
    "    PREDICTIONS = list()\n",
    "    \n",
    "    \n",
    "    num_batches = len(iteratore)\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, labels in tqdm(iteratore):\n",
    "            labels  = labels.type(torch.LongTensor)\n",
    "            img, labels = img.cuda(), labels.cuda()\n",
    "\n",
    "            pred = model(img)\n",
    "            test_loss += loss_f(pred, labels).item()\n",
    "            \n",
    "            \n",
    "            pred_indices = torch.argmax(pred, dim=1)\n",
    "            label_test = labels.cpu().float()\n",
    "            pred_indices = pred_indices.cpu().float()\n",
    "            distances = torch.where(pred_indices == label_test, torch.tensor(1), torch.tensor(0))\n",
    "            distances = distances.numpy()\n",
    "            accuracy += sum(distances)/len(label_test)\n",
    "            \n",
    "            PREDICTIONS += pred_indices.tolist()\n",
    "            LABELS += labels.tolist()\n",
    "            \n",
    "    print(f\"F1 Score, None = {f1_score(LABELS, PREDICTIONS, average=None)}\")\n",
    "    print(f\"F1 Score, micro = {f1_score(LABELS, PREDICTIONS, average='micro')}\")\n",
    "    print(f\"F1 Score, macro = {f1_score(LABELS, PREDICTIONS, average='macro')}\")\n",
    "    print(f\"F1 Score, avg = {f1_score(LABELS, PREDICTIONS, average='weighted')}\")\n",
    "            \n",
    "    test_loss = test_loss / num_batches\n",
    "    accuracy_tot = accuracy / num_batches\n",
    "    print(f\"Average TEST loss: {test_loss}, TEST accuracy: {accuracy_tot*100}%\")\n",
    "    return test_loss\n",
    "\n",
    "test_with_f1(model, val_loader, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc84ae0",
   "metadata": {},
   "source": [
    "## Final Plots - Visual Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "172e58f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "X = np.arange(len(train_losses))    \n",
    "Y = train_losses\n",
    "    \n",
    "    \n",
    "plt.plot(X, train_losses, label='TRAIN loss')\n",
    "plt.plot(X, test_losses, label='TEST loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig('model_losses_finale.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f71ba2",
   "metadata": {},
   "source": [
    "## Final Considerations\n",
    "\n",
    "The project successfully demonstrated the potential of CNNs in automating the identification process and contributing to cetacean research and conservation. Despite the challenges faced, the trained CNN model showcased commendable performance in distinguishing between different cetacean species. Consequently, through the practical application of the knowledge acquired during the course of this study, we successfully adapted our expertise to a field that impassions us greatly. This endeavor allowed us to realize the transformative effects of deploying general knowledge within a domain of personal interest, thereby fostering an elevated level of engagement and dedication to our academic pursuits. It instilled in us an unwavering enthusiasm to continuously raise the bar and strive towards the attainment of our goals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
